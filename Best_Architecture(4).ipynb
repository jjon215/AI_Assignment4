{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best Architecture(4).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW_2/blob/master/Best_Architecture(4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6MfO_BJ2EDJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a222df80-47f3-4ccc-d5b8-29e90fdcbad0"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "for i in range(5):\n",
        "  x_val = np.array(x_train[i*10000:(i+1)*10000])\n",
        "  y_val = np.array(y_train[i*10000:(i+1)*10000])\n",
        "  \n",
        "  x_tra = np.array(x_train[0:i*10000]+x_train[(i+1)*10000:50000])\n",
        "  y_tra = np.array(y_train[0:i*10000]+y_train[(i+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(32, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(64, (3, 3)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(128, (2, 2), padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(128, (2, 2)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False, \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False,  \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0,  \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0., \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0.,  \n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  \n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=False,  \n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "  datagen.fit(x_tra)\n",
        "\n",
        "  for e in range(10):\n",
        "      batches = 0\n",
        "      for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=50000):\n",
        "          model.fit(x_batch, y_batch)\n",
        "          batches += 1\n",
        "          if batches >= 1:\n",
        "              break\n",
        "\n",
        "  \n",
        "  History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "  score = model.evaluate(x_val, y_val, verbose=0)\n",
        "  print('Test loss is:', score[0])\n",
        "  print('Test accuracy is:', score[1])\n",
        "  print(score)\n",
        "  print(History.history)\n",
        "\n",
        "  plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "  plt.show(plotaccuracy)\n",
        "  \n",
        "  val_loss.append(History.history['val_loss'][-1])\n",
        "  val_acc.append(History.history['val_acc'][-1])\n",
        "\n",
        "avg_val_loss = 0\n",
        "avg_val_acc = 0\n",
        "for i in range(5):\n",
        "  avg_val_loss += val_loss[i]/5\n",
        "  avg_val_acc += val_acc[i]/5\n",
        "  \n",
        "print('Avgerage validation loss:',avg_val_loss)\n",
        "print('Average validation accuracy:',avg_val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "35200/40000 [=========================>....] - ETA: 2:15 - loss: 1.9953 - acc: 0.2444"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}