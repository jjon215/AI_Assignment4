{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_Arch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW_2/blob/master/First_Arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "G6L7SaOq9baK",
        "colab_type": "code",
        "outputId": "9b22acef-71c2-4fb4-b729-c0134fdc24ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4463
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "  \n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False, \n",
        "        zca_whitening=False,  \n",
        "        zca_epsilon=1e-06, \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  \n",
        "        zoom_range=0., \n",
        "        channel_shift_range=0., \n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  \n",
        "        horizontal_flip=True,  # flip images\n",
        "        vertical_flip=False,  # images\n",
        "        # applying rescaling factor\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test Loss is :', score[0])\n",
        "print('Test Accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('Validation Loss is :',History.history['val_loss'][-1])\n",
        "print('Validation Accuracy is :',History.history['val_acc'][-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 25s 630us/step - loss: 1.8945 - acc: 0.2885\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 25s 619us/step - loss: 1.5965 - acc: 0.4095\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 27s 671us/step - loss: 1.4726 - acc: 0.4604\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 25s 614us/step - loss: 1.3779 - acc: 0.4968\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 27s 667us/step - loss: 1.3118 - acc: 0.5278\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 24s 590us/step - loss: 1.2423 - acc: 0.5548\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 23s 577us/step - loss: 1.1983 - acc: 0.5711\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 23s 570us/step - loss: 1.1490 - acc: 0.5900\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 24s 599us/step - loss: 1.1029 - acc: 0.6091\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 26s 652us/step - loss: 1.0811 - acc: 0.6164\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 28s 712us/step - loss: 0.9563 - acc: 0.6627 - val_loss: 0.8650 - val_acc: 0.6965\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 27s 684us/step - loss: 0.9144 - acc: 0.6772 - val_loss: 0.8469 - val_acc: 0.7010\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 29s 713us/step - loss: 0.8815 - acc: 0.6904 - val_loss: 0.8124 - val_acc: 0.7124\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 29s 713us/step - loss: 0.8449 - acc: 0.7026 - val_loss: 0.7889 - val_acc: 0.7243\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 28s 698us/step - loss: 0.8155 - acc: 0.7141 - val_loss: 0.7660 - val_acc: 0.7339\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 28s 706us/step - loss: 0.7858 - acc: 0.7263 - val_loss: 0.7515 - val_acc: 0.7363\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 28s 691us/step - loss: 0.7581 - acc: 0.7339 - val_loss: 0.7232 - val_acc: 0.7511\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 28s 690us/step - loss: 0.7369 - acc: 0.7403 - val_loss: 0.7125 - val_acc: 0.7517\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 25s 624us/step - loss: 0.7185 - acc: 0.7490 - val_loss: 0.6979 - val_acc: 0.7578\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 27s 676us/step - loss: 0.6946 - acc: 0.7558 - val_loss: 0.6953 - val_acc: 0.7576\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.6735 - acc: 0.7635 - val_loss: 0.6958 - val_acc: 0.7615\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.6539 - acc: 0.7699 - val_loss: 0.6656 - val_acc: 0.7671\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.6367 - acc: 0.7767 - val_loss: 0.6680 - val_acc: 0.7699\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 26s 661us/step - loss: 0.6198 - acc: 0.7810 - val_loss: 0.6705 - val_acc: 0.7718\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.5999 - acc: 0.7900 - val_loss: 0.6588 - val_acc: 0.7737\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 27s 683us/step - loss: 0.5853 - acc: 0.7932 - val_loss: 0.6719 - val_acc: 0.7713\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 27s 683us/step - loss: 0.5695 - acc: 0.7996 - val_loss: 0.6285 - val_acc: 0.7827\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 29s 719us/step - loss: 0.5580 - acc: 0.8035 - val_loss: 0.6456 - val_acc: 0.7791\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 28s 706us/step - loss: 0.5423 - acc: 0.8096 - val_loss: 0.6198 - val_acc: 0.7872\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 28s 709us/step - loss: 0.5279 - acc: 0.8148 - val_loss: 0.6172 - val_acc: 0.7868\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 29s 714us/step - loss: 0.5151 - acc: 0.8185 - val_loss: 0.6279 - val_acc: 0.7887\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 29s 719us/step - loss: 0.5020 - acc: 0.8250 - val_loss: 0.6072 - val_acc: 0.7908\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 28s 708us/step - loss: 0.4916 - acc: 0.8276 - val_loss: 0.6101 - val_acc: 0.7927\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 29s 716us/step - loss: 0.4749 - acc: 0.8318 - val_loss: 0.6261 - val_acc: 0.7933\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 29s 716us/step - loss: 0.4669 - acc: 0.8328 - val_loss: 0.6114 - val_acc: 0.7959\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 29s 720us/step - loss: 0.4578 - acc: 0.8389 - val_loss: 0.6014 - val_acc: 0.8011\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 28s 707us/step - loss: 0.4394 - acc: 0.8438 - val_loss: 0.6022 - val_acc: 0.7943\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 28s 701us/step - loss: 0.4401 - acc: 0.8445 - val_loss: 0.6099 - val_acc: 0.7947\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 28s 702us/step - loss: 0.4221 - acc: 0.8506 - val_loss: 0.5913 - val_acc: 0.7989\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 28s 690us/step - loss: 0.4119 - acc: 0.8541 - val_loss: 0.6071 - val_acc: 0.7995\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 27s 684us/step - loss: 0.4040 - acc: 0.8565 - val_loss: 0.5982 - val_acc: 0.8029\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 27s 682us/step - loss: 0.3908 - acc: 0.8619 - val_loss: 0.6052 - val_acc: 0.8018\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 28s 695us/step - loss: 0.3814 - acc: 0.8624 - val_loss: 0.5962 - val_acc: 0.8054\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 29s 719us/step - loss: 0.3746 - acc: 0.8665 - val_loss: 0.6144 - val_acc: 0.8021\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 29s 720us/step - loss: 0.3632 - acc: 0.8715 - val_loss: 0.6259 - val_acc: 0.7964\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 29s 713us/step - loss: 0.3575 - acc: 0.8728 - val_loss: 0.6114 - val_acc: 0.8027\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 29s 715us/step - loss: 0.3509 - acc: 0.8748 - val_loss: 0.6199 - val_acc: 0.8013\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 29s 717us/step - loss: 0.3413 - acc: 0.8776 - val_loss: 0.6098 - val_acc: 0.8065\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 29s 715us/step - loss: 0.3324 - acc: 0.8823 - val_loss: 0.6128 - val_acc: 0.8055\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 28s 705us/step - loss: 0.3263 - acc: 0.8829 - val_loss: 0.6024 - val_acc: 0.8084\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 28s 695us/step - loss: 0.3189 - acc: 0.8861 - val_loss: 0.6090 - val_acc: 0.8051\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 28s 695us/step - loss: 0.3101 - acc: 0.8896 - val_loss: 0.6104 - val_acc: 0.8044\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 28s 690us/step - loss: 0.3034 - acc: 0.8910 - val_loss: 0.6205 - val_acc: 0.8063\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 27s 679us/step - loss: 0.2979 - acc: 0.8934 - val_loss: 0.6228 - val_acc: 0.8074\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 27s 678us/step - loss: 0.2949 - acc: 0.8952 - val_loss: 0.6308 - val_acc: 0.8048\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 24s 588us/step - loss: 0.2844 - acc: 0.8981 - val_loss: 0.6251 - val_acc: 0.8073\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 23s 566us/step - loss: 0.2817 - acc: 0.8978 - val_loss: 0.6180 - val_acc: 0.8060\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 23s 563us/step - loss: 0.2722 - acc: 0.9030 - val_loss: 0.6188 - val_acc: 0.8105\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 25s 619us/step - loss: 0.2688 - acc: 0.9040 - val_loss: 0.6288 - val_acc: 0.8088\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 25s 632us/step - loss: 0.2654 - acc: 0.9053 - val_loss: 0.6349 - val_acc: 0.8065\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 28s 691us/step - loss: 0.2538 - acc: 0.9080 - val_loss: 0.6334 - val_acc: 0.8054\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 28s 688us/step - loss: 0.2539 - acc: 0.9082 - val_loss: 0.6351 - val_acc: 0.8108\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 29s 720us/step - loss: 0.2463 - acc: 0.9131 - val_loss: 0.6415 - val_acc: 0.8116\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 28s 712us/step - loss: 0.2381 - acc: 0.9165 - val_loss: 0.6538 - val_acc: 0.8075\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 28s 710us/step - loss: 0.2376 - acc: 0.9129 - val_loss: 0.6370 - val_acc: 0.8101\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 28s 708us/step - loss: 0.2294 - acc: 0.9181 - val_loss: 0.6569 - val_acc: 0.8081\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 29s 716us/step - loss: 0.2233 - acc: 0.9195 - val_loss: 0.6670 - val_acc: 0.8088\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 25s 629us/step - loss: 0.2250 - acc: 0.9194 - val_loss: 0.6435 - val_acc: 0.8114\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 27s 672us/step - loss: 0.2188 - acc: 0.9202 - val_loss: 0.6563 - val_acc: 0.8118\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.2143 - acc: 0.9234 - val_loss: 0.6562 - val_acc: 0.8155\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 26s 662us/step - loss: 0.2095 - acc: 0.9247 - val_loss: 0.6559 - val_acc: 0.8102\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 28s 700us/step - loss: 0.2059 - acc: 0.9260 - val_loss: 0.6861 - val_acc: 0.8070\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 28s 694us/step - loss: 0.1991 - acc: 0.9284 - val_loss: 0.6665 - val_acc: 0.8124\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 27s 682us/step - loss: 0.2025 - acc: 0.9285 - val_loss: 0.6857 - val_acc: 0.8100\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 27s 680us/step - loss: 0.1954 - acc: 0.9289 - val_loss: 0.6895 - val_acc: 0.8113\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 27s 682us/step - loss: 0.1901 - acc: 0.9325 - val_loss: 0.6665 - val_acc: 0.8122\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 27s 684us/step - loss: 0.1937 - acc: 0.9312 - val_loss: 0.6799 - val_acc: 0.8089\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 27s 685us/step - loss: 0.1904 - acc: 0.9312 - val_loss: 0.6756 - val_acc: 0.8148\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 28s 698us/step - loss: 0.1858 - acc: 0.9348 - val_loss: 0.7024 - val_acc: 0.8087\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 28s 703us/step - loss: 0.1809 - acc: 0.9357 - val_loss: 0.6892 - val_acc: 0.8130\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 28s 703us/step - loss: 0.1770 - acc: 0.9372 - val_loss: 0.6872 - val_acc: 0.8134\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 28s 704us/step - loss: 0.1723 - acc: 0.9379 - val_loss: 0.6901 - val_acc: 0.8107\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 28s 707us/step - loss: 0.1681 - acc: 0.9393 - val_loss: 0.6910 - val_acc: 0.8146\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 28s 697us/step - loss: 0.1690 - acc: 0.9405 - val_loss: 0.7044 - val_acc: 0.8123\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 27s 683us/step - loss: 0.1672 - acc: 0.9399 - val_loss: 0.6920 - val_acc: 0.8146\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 27s 681us/step - loss: 0.1667 - acc: 0.9405 - val_loss: 0.6949 - val_acc: 0.8108\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 27s 680us/step - loss: 0.1567 - acc: 0.9440 - val_loss: 0.7072 - val_acc: 0.8085\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 27s 667us/step - loss: 0.1602 - acc: 0.9438 - val_loss: 0.7175 - val_acc: 0.8127\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 27s 678us/step - loss: 0.1529 - acc: 0.9456 - val_loss: 0.7245 - val_acc: 0.8072\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 32s 791us/step - loss: 0.1568 - acc: 0.9448 - val_loss: 0.7179 - val_acc: 0.8111\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 29s 719us/step - loss: 0.1523 - acc: 0.9456 - val_loss: 0.7219 - val_acc: 0.8160\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 29s 735us/step - loss: 0.1440 - acc: 0.9480 - val_loss: 0.7571 - val_acc: 0.8051\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 30s 740us/step - loss: 0.1525 - acc: 0.9469 - val_loss: 0.7262 - val_acc: 0.8152\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 30s 742us/step - loss: 0.1438 - acc: 0.9486 - val_loss: 0.7248 - val_acc: 0.8154\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 30s 745us/step - loss: 0.1428 - acc: 0.9495 - val_loss: 0.7481 - val_acc: 0.8097\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 29s 731us/step - loss: 0.1440 - acc: 0.9499 - val_loss: 0.7269 - val_acc: 0.8121\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 27s 687us/step - loss: 0.1433 - acc: 0.9499 - val_loss: 0.7194 - val_acc: 0.8105\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 27s 683us/step - loss: 0.1395 - acc: 0.9509 - val_loss: 0.7091 - val_acc: 0.8165\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 29s 725us/step - loss: 0.1362 - acc: 0.9521 - val_loss: 0.7690 - val_acc: 0.8070\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 30s 740us/step - loss: 0.1324 - acc: 0.9533 - val_loss: 0.7355 - val_acc: 0.8141\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 30s 740us/step - loss: 0.1354 - acc: 0.9512 - val_loss: 0.7437 - val_acc: 0.8110\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 30s 739us/step - loss: 0.1317 - acc: 0.9534 - val_loss: 0.7335 - val_acc: 0.8163\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 30s 741us/step - loss: 0.1321 - acc: 0.9535 - val_loss: 0.7388 - val_acc: 0.8109\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 29s 725us/step - loss: 0.1273 - acc: 0.9556 - val_loss: 0.7895 - val_acc: 0.8102\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 28s 709us/step - loss: 0.1299 - acc: 0.9541 - val_loss: 0.7634 - val_acc: 0.8129\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 29s 716us/step - loss: 0.1259 - acc: 0.9567 - val_loss: 0.7463 - val_acc: 0.8174\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 29s 721us/step - loss: 0.1251 - acc: 0.9551 - val_loss: 0.7481 - val_acc: 0.8157\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 29s 731us/step - loss: 0.1215 - acc: 0.9576 - val_loss: 0.7349 - val_acc: 0.8130\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 30s 743us/step - loss: 0.1251 - acc: 0.9560 - val_loss: 0.7627 - val_acc: 0.8149\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 30s 740us/step - loss: 0.1213 - acc: 0.9586 - val_loss: 0.7496 - val_acc: 0.8190\n",
            "Test Loss is : 0.7496384120941162\n",
            "Test Accuracy: 0.819\n",
            "[0.7496384120941162, 0.819]\n",
            "{'val_loss': [0.8650298462867737, 0.8469300411224365, 0.8123863375663757, 0.7889357526779175, 0.7659964842796325, 0.7515000098228455, 0.7231724052429199, 0.7124518657684327, 0.6978969172477723, 0.6953148925304413, 0.6958261876106262, 0.6656133178710938, 0.6680235088348389, 0.6705487024307251, 0.6587962560653686, 0.6719308382987976, 0.6284951420783996, 0.645619216632843, 0.6197702036380768, 0.6172228972911835, 0.6279222350120545, 0.6072396200656891, 0.6101464296340943, 0.6260814063072204, 0.6113707697868347, 0.601381979894638, 0.6022106972694397, 0.6099111918926239, 0.5912628377914428, 0.6070739756107331, 0.5981513279914856, 0.6051520940303803, 0.5961990911960602, 0.614380073595047, 0.6258719938278198, 0.6113666367053986, 0.6199268763542175, 0.6097517912387848, 0.6128079010486602, 0.6023563640117645, 0.609044037771225, 0.6103644020557404, 0.6205257129669189, 0.6227773405313491, 0.630767119884491, 0.6250604189872742, 0.6179945537567139, 0.6187582339763641, 0.6287684238433838, 0.6349149884223938, 0.633356968998909, 0.635061761021614, 0.6415071542501449, 0.6538227435112, 0.6370419283866883, 0.6568941954612731, 0.6669764332294464, 0.6434664619922638, 0.6562564393043518, 0.6562294728279113, 0.6559021476745606, 0.6860836483240128, 0.6665056874513626, 0.6857116360664368, 0.6894661001086235, 0.6665372494220734, 0.679896596288681, 0.6756480038642884, 0.7024005190134048, 0.6892478650808335, 0.68718430519104, 0.6900845423698425, 0.691004009103775, 0.7043943394899368, 0.6919962574958801, 0.6948524766206742, 0.7071639071464538, 0.7175195659875869, 0.7245469998121261, 0.7178513520956039, 0.7218898658275604, 0.757149284529686, 0.7261548942327499, 0.7247843208789826, 0.7481061980247498, 0.7268518397092819, 0.7194154215335846, 0.7091135613203049, 0.768987924003601, 0.7355207375526428, 0.7436837696313858, 0.733549697303772, 0.7387628677368164, 0.7894973418474197, 0.7633643989562988, 0.7462748034715653, 0.7481374463915825, 0.7349383231639862, 0.7626805205106735, 0.7496384120941162], 'val_acc': [0.6965, 0.701, 0.7124, 0.7243, 0.7339, 0.7363, 0.7511, 0.7517, 0.7578, 0.7576, 0.7615, 0.7671, 0.7699, 0.7718, 0.7737, 0.7713, 0.7827, 0.7791, 0.7872, 0.7868, 0.7887, 0.7908, 0.7927, 0.7933, 0.7959, 0.8011, 0.7943, 0.7947, 0.7989, 0.7995, 0.8029, 0.8018, 0.8054, 0.8021, 0.7964, 0.8027, 0.8013, 0.8065, 0.8055, 0.8084, 0.8051, 0.8044, 0.8063, 0.8074, 0.8048, 0.8073, 0.806, 0.8105, 0.8088, 0.8065, 0.8054, 0.8108, 0.8116, 0.8075, 0.8101, 0.8081, 0.8088, 0.8114, 0.8118, 0.8155, 0.8102, 0.807, 0.8124, 0.81, 0.8113, 0.8122, 0.8089, 0.8148, 0.8087, 0.813, 0.8134, 0.8107, 0.8146, 0.8123, 0.8146, 0.8108, 0.8085, 0.8127, 0.8072, 0.8111, 0.816, 0.8051, 0.8152, 0.8154, 0.8097, 0.8121, 0.8105, 0.8165, 0.807, 0.8141, 0.811, 0.8163, 0.8109, 0.8102, 0.8129, 0.8174, 0.8157, 0.813, 0.8149, 0.819], 'loss': [0.9563274575710297, 0.9143612351417542, 0.8814940716981888, 0.8449071444749832, 0.8155115005254745, 0.7857646879911423, 0.7581304116010665, 0.7368738557100296, 0.7185124214887619, 0.6946195557594299, 0.6734947813034058, 0.6539151368379593, 0.6366610218167305, 0.6198249578118324, 0.5999475652456283, 0.5852959669113159, 0.5695075681209564, 0.5579618239760399, 0.5422597727894783, 0.5278979670763015, 0.5150759710431099, 0.5019782087802886, 0.4916229910671711, 0.4748931275069714, 0.46690702081918717, 0.45779047359228137, 0.43937658261060714, 0.44013955143094063, 0.4220723413586617, 0.41185167357325553, 0.40398519476652145, 0.39078305388092993, 0.381441123098135, 0.37456141348481176, 0.3631992871284485, 0.3574989261090755, 0.3508720969080925, 0.34128311545848844, 0.3323904715716839, 0.32628360117077826, 0.3188502192318439, 0.3101473332494497, 0.3034493229418993, 0.2978926725834608, 0.2949008660942316, 0.28442217680215837, 0.2817274661898613, 0.27223796648681164, 0.2687820938795805, 0.26540879802405837, 0.25378989987969397, 0.2539388560175896, 0.24626640753000975, 0.23810697363168, 0.2375536526978016, 0.22937366355657576, 0.22331418870836497, 0.2249513998836279, 0.2188123673543334, 0.21432207331955433, 0.20945316589176655, 0.20591159238964318, 0.1991142936438322, 0.2025206580042839, 0.1953610803693533, 0.19010085145384073, 0.1937159790635109, 0.19040462156534194, 0.1857616861537099, 0.18085142317190767, 0.17695095444768666, 0.17226944815218448, 0.16806791847124697, 0.16900999545827508, 0.16719342353641986, 0.166672967235744, 0.15672953482717275, 0.16020084984805436, 0.15294256743490697, 0.15680130329579114, 0.15231964590866118, 0.1440360564365983, 0.15249581353515387, 0.14384802710413933, 0.14277530415542425, 0.143981688304618, 0.14331756921708583, 0.1395148553635925, 0.1361704979300499, 0.1324435485392809, 0.13542476097084583, 0.131703715704754, 0.13212544772438706, 0.12725168815143406, 0.1298528762228787, 0.12592300988212227, 0.12508953013569116, 0.12154698333479463, 0.12508512285016476, 0.12129657692983746], 'acc': [0.66275, 0.677175, 0.6904, 0.702625, 0.71405, 0.7263, 0.733925, 0.740275, 0.749, 0.755775, 0.763475, 0.7699, 0.77665, 0.781025, 0.79, 0.79325, 0.7996, 0.8035, 0.8096, 0.81485, 0.8185, 0.824975, 0.827575, 0.83175, 0.8328, 0.8389, 0.843825, 0.8445, 0.850575, 0.854075, 0.85645, 0.861875, 0.8624, 0.866475, 0.871525, 0.872825, 0.874775, 0.8776, 0.882325, 0.88295, 0.88615, 0.88955, 0.89095, 0.893425, 0.89515, 0.898075, 0.897775, 0.902975, 0.904025, 0.90535, 0.907975, 0.9082, 0.913125, 0.916475, 0.9129, 0.9181, 0.919475, 0.919425, 0.920225, 0.9234, 0.924675, 0.925975, 0.9284, 0.9285, 0.92895, 0.93245, 0.931225, 0.9312, 0.9348, 0.9357, 0.937225, 0.937875, 0.9393, 0.940475, 0.9399, 0.94055, 0.943975, 0.9438, 0.94565, 0.944825, 0.945625, 0.948025, 0.9469, 0.9486, 0.94945, 0.949925, 0.949875, 0.95095, 0.95205, 0.953275, 0.95115, 0.953425, 0.95345, 0.955625, 0.9541, 0.95665, 0.95505, 0.957575, 0.95595, 0.958575]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN5tlWfFj1apGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Loss is : 0.7496384120941162\n",
            "Validation Accuracy is : 0.819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGdU88vaEzUc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHmaUUDnE0CF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bky6xMEXE0bX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}