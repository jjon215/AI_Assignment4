{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Second_Arch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW_2/blob/master/Second_Arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "paJvad_4A8vt",
        "colab_type": "code",
        "outputId": "7f3793bd-5eb7-40ac-d58d-140300288e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4446
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=x_tra.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "            # we need to break the loop by hand because\n",
        "            # the generator loops indefinitely\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('validation loss:',History.history['val_loss'][-1])\n",
        "print('validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 34s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 19s 482us/step - loss: 1.8922 - acc: 0.3143\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 13s 325us/step - loss: 1.6088 - acc: 0.4205\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 14s 350us/step - loss: 1.5181 - acc: 0.4522\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 1.4713 - acc: 0.4696\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 13s 337us/step - loss: 1.4313 - acc: 0.4860\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 1.3975 - acc: 0.4975\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 1.3696 - acc: 0.5068\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 1.3424 - acc: 0.5202\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 1.3215 - acc: 0.5266\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 12s 311us/step - loss: 1.2981 - acc: 0.5358\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 14s 357us/step - loss: 1.1786 - acc: 0.5812 - val_loss: 1.1785 - val_acc: 0.5851\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 15s 370us/step - loss: 1.1448 - acc: 0.5934 - val_loss: 1.1726 - val_acc: 0.5855\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 1.1169 - acc: 0.6058 - val_loss: 1.1441 - val_acc: 0.5958\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 1.0948 - acc: 0.6141 - val_loss: 1.1188 - val_acc: 0.6063\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 1.0694 - acc: 0.6228 - val_loss: 1.1165 - val_acc: 0.6090\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 14s 348us/step - loss: 1.0509 - acc: 0.6314 - val_loss: 1.1253 - val_acc: 0.6057\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 14s 355us/step - loss: 1.0299 - acc: 0.6367 - val_loss: 1.0910 - val_acc: 0.6223\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 15s 376us/step - loss: 1.0120 - acc: 0.6437 - val_loss: 1.0716 - val_acc: 0.6259\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 15s 377us/step - loss: 0.9934 - acc: 0.6505 - val_loss: 1.0909 - val_acc: 0.6221\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 15s 380us/step - loss: 0.9763 - acc: 0.6566 - val_loss: 1.0641 - val_acc: 0.6286\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 14s 352us/step - loss: 0.9603 - acc: 0.6632 - val_loss: 1.0389 - val_acc: 0.6394\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 13s 331us/step - loss: 0.9409 - acc: 0.6708 - val_loss: 1.0323 - val_acc: 0.6351\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 13s 326us/step - loss: 0.9265 - acc: 0.6766 - val_loss: 1.0354 - val_acc: 0.6394\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.9121 - acc: 0.6815 - val_loss: 1.0213 - val_acc: 0.6460\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 16s 392us/step - loss: 0.8944 - acc: 0.6871 - val_loss: 1.0239 - val_acc: 0.6434\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 16s 397us/step - loss: 0.8796 - acc: 0.6939 - val_loss: 1.0168 - val_acc: 0.6506\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 16s 406us/step - loss: 0.8658 - acc: 0.6972 - val_loss: 1.0163 - val_acc: 0.6505\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 16s 401us/step - loss: 0.8516 - acc: 0.7034 - val_loss: 1.0011 - val_acc: 0.6558\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.8382 - acc: 0.7092 - val_loss: 0.9899 - val_acc: 0.6631\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.8256 - acc: 0.7097 - val_loss: 0.9804 - val_acc: 0.6635\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 15s 371us/step - loss: 0.8127 - acc: 0.7179 - val_loss: 0.9798 - val_acc: 0.6676\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.7975 - acc: 0.7233 - val_loss: 0.9977 - val_acc: 0.6634\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 15s 371us/step - loss: 0.7850 - acc: 0.7279 - val_loss: 0.9745 - val_acc: 0.6676\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 0.7737 - acc: 0.7311 - val_loss: 0.9746 - val_acc: 0.6660\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 15s 365us/step - loss: 0.7609 - acc: 0.7354 - val_loss: 0.9624 - val_acc: 0.6750\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.7491 - acc: 0.7404 - val_loss: 0.9734 - val_acc: 0.6644\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 0.7372 - acc: 0.7426 - val_loss: 0.9697 - val_acc: 0.6710\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 0.7248 - acc: 0.7511 - val_loss: 0.9494 - val_acc: 0.6773\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.7139 - acc: 0.7553 - val_loss: 0.9657 - val_acc: 0.6716\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 0.7035 - acc: 0.7573 - val_loss: 0.9505 - val_acc: 0.6778\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.6902 - acc: 0.7617 - val_loss: 0.9871 - val_acc: 0.6647\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 14s 359us/step - loss: 0.6812 - acc: 0.7658 - val_loss: 0.9570 - val_acc: 0.6791\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.6698 - acc: 0.7694 - val_loss: 0.9607 - val_acc: 0.6787\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.6593 - acc: 0.7737 - val_loss: 0.9539 - val_acc: 0.6835\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.6468 - acc: 0.7795 - val_loss: 0.9519 - val_acc: 0.6810\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 0.6371 - acc: 0.7812 - val_loss: 0.9550 - val_acc: 0.6800\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 14s 344us/step - loss: 0.6265 - acc: 0.7851 - val_loss: 0.9841 - val_acc: 0.6736\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 14s 351us/step - loss: 0.6171 - acc: 0.7889 - val_loss: 0.9558 - val_acc: 0.6787\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 15s 368us/step - loss: 0.6064 - acc: 0.7925 - val_loss: 0.9753 - val_acc: 0.6766\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 15s 368us/step - loss: 0.5959 - acc: 0.7972 - val_loss: 0.9820 - val_acc: 0.6790\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 14s 358us/step - loss: 0.5859 - acc: 0.8003 - val_loss: 0.9706 - val_acc: 0.6855\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 14s 355us/step - loss: 0.5752 - acc: 0.8031 - val_loss: 0.9747 - val_acc: 0.6784\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 14s 345us/step - loss: 0.5663 - acc: 0.8083 - val_loss: 0.9853 - val_acc: 0.6796\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 13s 318us/step - loss: 0.5540 - acc: 0.8116 - val_loss: 0.9736 - val_acc: 0.6818\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 13s 326us/step - loss: 0.5462 - acc: 0.8128 - val_loss: 0.9984 - val_acc: 0.6794\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 13s 324us/step - loss: 0.5360 - acc: 0.8184 - val_loss: 0.9777 - val_acc: 0.6801\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 14s 343us/step - loss: 0.5256 - acc: 0.8217 - val_loss: 0.9966 - val_acc: 0.6825\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 14s 346us/step - loss: 0.5160 - acc: 0.8249 - val_loss: 1.0053 - val_acc: 0.6789\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.5077 - acc: 0.8292 - val_loss: 1.0010 - val_acc: 0.6786\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.4986 - acc: 0.8322 - val_loss: 1.0161 - val_acc: 0.6803\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 0.4898 - acc: 0.8365 - val_loss: 1.0138 - val_acc: 0.6785\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 15s 366us/step - loss: 0.4782 - acc: 0.8408 - val_loss: 1.0072 - val_acc: 0.6846\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.4696 - acc: 0.8411 - val_loss: 1.0355 - val_acc: 0.6820\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 14s 357us/step - loss: 0.4616 - acc: 0.8447 - val_loss: 1.0260 - val_acc: 0.6857\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 14s 356us/step - loss: 0.4492 - acc: 0.8477 - val_loss: 1.0314 - val_acc: 0.6803\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 15s 365us/step - loss: 0.4415 - acc: 0.8533 - val_loss: 1.0859 - val_acc: 0.6754\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 15s 366us/step - loss: 0.4318 - acc: 0.8549 - val_loss: 1.0513 - val_acc: 0.6776\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.4214 - acc: 0.8581 - val_loss: 1.0843 - val_acc: 0.6694\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.4142 - acc: 0.8617 - val_loss: 1.0726 - val_acc: 0.6771\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 15s 365us/step - loss: 0.4080 - acc: 0.8649 - val_loss: 1.1322 - val_acc: 0.6693\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.3982 - acc: 0.8673 - val_loss: 1.0966 - val_acc: 0.6808\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 0.3863 - acc: 0.8710 - val_loss: 1.0838 - val_acc: 0.6812\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 14s 356us/step - loss: 0.3800 - acc: 0.8738 - val_loss: 1.0840 - val_acc: 0.6830\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 14s 338us/step - loss: 0.3707 - acc: 0.8778 - val_loss: 1.1051 - val_acc: 0.6845\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 14s 358us/step - loss: 0.3604 - acc: 0.8810 - val_loss: 1.1265 - val_acc: 0.6782\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 14s 356us/step - loss: 0.3533 - acc: 0.8837 - val_loss: 1.1343 - val_acc: 0.6791\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 14s 347us/step - loss: 0.3449 - acc: 0.8873 - val_loss: 1.1339 - val_acc: 0.6782\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 13s 337us/step - loss: 0.3340 - acc: 0.8919 - val_loss: 1.1830 - val_acc: 0.6652\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 14s 346us/step - loss: 0.3281 - acc: 0.8923 - val_loss: 1.1597 - val_acc: 0.6794\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 14s 339us/step - loss: 0.3205 - acc: 0.8949 - val_loss: 1.1729 - val_acc: 0.6741\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 14s 360us/step - loss: 0.3119 - acc: 0.8997 - val_loss: 1.1973 - val_acc: 0.6738\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.3052 - acc: 0.9021 - val_loss: 1.2233 - val_acc: 0.6720\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.2968 - acc: 0.9051 - val_loss: 1.2091 - val_acc: 0.6811\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.2887 - acc: 0.9082 - val_loss: 1.2378 - val_acc: 0.6711\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 15s 365us/step - loss: 0.2815 - acc: 0.9099 - val_loss: 1.2306 - val_acc: 0.6765\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 15s 363us/step - loss: 0.2709 - acc: 0.9135 - val_loss: 1.2493 - val_acc: 0.6762\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 15s 364us/step - loss: 0.2616 - acc: 0.9173 - val_loss: 1.2621 - val_acc: 0.6757\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.2576 - acc: 0.9184 - val_loss: 1.2764 - val_acc: 0.6738\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 14s 357us/step - loss: 0.2474 - acc: 0.9220 - val_loss: 1.3246 - val_acc: 0.6710\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 14s 349us/step - loss: 0.2417 - acc: 0.9238 - val_loss: 1.3182 - val_acc: 0.6751\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 13s 334us/step - loss: 0.2349 - acc: 0.9282 - val_loss: 1.3272 - val_acc: 0.6730\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 14s 349us/step - loss: 0.2272 - acc: 0.9295 - val_loss: 1.3525 - val_acc: 0.6731\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 13s 323us/step - loss: 0.2214 - acc: 0.9319 - val_loss: 1.3564 - val_acc: 0.6763\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 13s 331us/step - loss: 0.2125 - acc: 0.9354 - val_loss: 1.4104 - val_acc: 0.6742\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 13s 327us/step - loss: 0.2056 - acc: 0.9373 - val_loss: 1.4217 - val_acc: 0.6687\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 15s 376us/step - loss: 0.1997 - acc: 0.9384 - val_loss: 1.4154 - val_acc: 0.6691\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 16s 392us/step - loss: 0.1917 - acc: 0.9431 - val_loss: 1.4199 - val_acc: 0.6678\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 15s 377us/step - loss: 0.1863 - acc: 0.9444 - val_loss: 1.4546 - val_acc: 0.6702\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 14s 353us/step - loss: 0.1782 - acc: 0.9478 - val_loss: 1.4482 - val_acc: 0.6674\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 15s 367us/step - loss: 0.1725 - acc: 0.9499 - val_loss: 1.4935 - val_acc: 0.6704\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 15s 384us/step - loss: 0.1644 - acc: 0.9536 - val_loss: 1.5232 - val_acc: 0.6686\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 15s 365us/step - loss: 0.1610 - acc: 0.9532 - val_loss: 1.5211 - val_acc: 0.6704\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 14s 345us/step - loss: 0.1548 - acc: 0.9553 - val_loss: 1.5668 - val_acc: 0.6671\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 15s 368us/step - loss: 0.1501 - acc: 0.9583 - val_loss: 1.5573 - val_acc: 0.6719\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 15s 375us/step - loss: 0.1431 - acc: 0.9603 - val_loss: 1.5978 - val_acc: 0.6676\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 14s 357us/step - loss: 0.1354 - acc: 0.9628 - val_loss: 1.6397 - val_acc: 0.6680\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 14s 351us/step - loss: 0.1316 - acc: 0.9638 - val_loss: 1.6922 - val_acc: 0.6666\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 14s 349us/step - loss: 0.1260 - acc: 0.9658 - val_loss: 1.6733 - val_acc: 0.6669\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 0.1236 - acc: 0.9660 - val_loss: 1.6734 - val_acc: 0.6657\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 14s 361us/step - loss: 0.1133 - acc: 0.9708 - val_loss: 1.6918 - val_acc: 0.6665\n",
            "Test loss: 1.6917810311317445\n",
            "Test accuracy: 0.6665\n",
            "[1.6917810311317445, 0.6665]\n",
            "{'val_loss': [1.1784564573287963, 1.1726291255950927, 1.144114366531372, 1.1187778114318847, 1.116470578765869, 1.1252604347229005, 1.0910123579025268, 1.0716139204025268, 1.0909130207061768, 1.0640938302993774, 1.038905765724182, 1.0323250602722167, 1.0354221824645997, 1.0212948897361755, 1.0239385989189147, 1.016768717765808, 1.0163115911483764, 1.001136148262024, 0.9898743352890015, 0.9803975200653077, 0.9797646475791931, 0.9976758539199829, 0.9745174425125122, 0.9745555904388428, 0.9624467772483826, 0.9734135662078858, 0.9697403940200806, 0.9493699288368225, 0.9656646596908569, 0.9504774910926819, 0.9870853742599487, 0.9569761969566345, 0.9606554676055908, 0.9539165445327759, 0.951913408946991, 0.9549501024246215, 0.9841247909545898, 0.9557903686523438, 0.975250013256073, 0.9819676536560059, 0.970591893863678, 0.9747151244163513, 0.9853157291412353, 0.9735969682693482, 0.9984484111785888, 0.9777024410247803, 0.9966312060356141, 1.005345998096466, 1.0009722917556763, 1.016118717288971, 1.0137957033157348, 1.007193172645569, 1.035454933834076, 1.0259625846862792, 1.031400617980957, 1.0858817785263062, 1.0513301210403443, 1.0842645764350891, 1.0725890367507935, 1.1321793380737304, 1.0965867568016052, 1.0838010537147522, 1.0840483426094054, 1.1051318069458007, 1.126507092666626, 1.1343414101600646, 1.1338708720207213, 1.1829568738937377, 1.1596606746673583, 1.172898791408539, 1.1972580089569091, 1.2233287761688232, 1.2091185835838318, 1.2377994544029236, 1.2306193140983581, 1.2493285202026367, 1.2620774564743042, 1.2764099638938904, 1.32457662858963, 1.3182045202255248, 1.3271511905670166, 1.352528528213501, 1.3563700563430787, 1.410441991329193, 1.4217418729782105, 1.4154165517807007, 1.4199002965927123, 1.454602726840973, 1.4482066791534425, 1.493519400024414, 1.5232472506523131, 1.5210540572166442, 1.5668178471565246, 1.5572600534439087, 1.5977588136672973, 1.6396887671470641, 1.6921855331420899, 1.6732571845054627, 1.6734303737640381, 1.6917810311317445], 'val_acc': [0.5851, 0.5855, 0.5958, 0.6063, 0.609, 0.6057, 0.6223, 0.6259, 0.6221, 0.6286, 0.6394, 0.6351, 0.6394, 0.646, 0.6434, 0.6506, 0.6505, 0.6558, 0.6631, 0.6635, 0.6676, 0.6634, 0.6676, 0.666, 0.675, 0.6644, 0.671, 0.6773, 0.6716, 0.6778, 0.6647, 0.6791, 0.6787, 0.6835, 0.681, 0.68, 0.6736, 0.6787, 0.6766, 0.679, 0.6855, 0.6784, 0.6796, 0.6818, 0.6794, 0.6801, 0.6825, 0.6789, 0.6786, 0.6803, 0.6785, 0.6846, 0.682, 0.6857, 0.6803, 0.6754, 0.6776, 0.6694, 0.6771, 0.6693, 0.6808, 0.6812, 0.683, 0.6845, 0.6782, 0.6791, 0.6782, 0.6652, 0.6794, 0.6741, 0.6738, 0.672, 0.6811, 0.6711, 0.6765, 0.6762, 0.6757, 0.6738, 0.671, 0.6751, 0.673, 0.6731, 0.6763, 0.6742, 0.6687, 0.6691, 0.6678, 0.6702, 0.6674, 0.6704, 0.6686, 0.6704, 0.6671, 0.6719, 0.6676, 0.668, 0.6666, 0.6669, 0.6657, 0.6665], 'loss': [1.1786002714157104, 1.1447921663284302, 1.1169223953723908, 1.0947551413059236, 1.069397964334488, 1.0508912885189057, 1.0298668902397157, 1.011962815093994, 0.9933961930274964, 0.9762741755008697, 0.9603348050117493, 0.9409337436199188, 0.9265175708293915, 0.912090364074707, 0.8944234107017517, 0.8795534493207932, 0.8658424006462098, 0.8515893606901169, 0.838190915131569, 0.8256067159891128, 0.8126625960588455, 0.797512602186203, 0.784962904715538, 0.7737258699893952, 0.7609336183547973, 0.7490604580163955, 0.7372002683877945, 0.7247598461151123, 0.7138644282341003, 0.7034950001001358, 0.6902363102316856, 0.6811799880027771, 0.6697549509048462, 0.6593386890649795, 0.64680762424469, 0.6371202271223069, 0.6265457176923752, 0.6170565790295601, 0.6063828313469887, 0.5958949607491493, 0.5858738977313042, 0.5751847502589226, 0.5663121743440628, 0.5540268944382668, 0.546166809785366, 0.536026125907898, 0.5256489846110344, 0.5160466264247894, 0.507690957570076, 0.49856109669208526, 0.4898242138981819, 0.47824684957265856, 0.46961231452226637, 0.46156045895814896, 0.44924752156734465, 0.4414805624127388, 0.4317886197865009, 0.42139301862716677, 0.41422078297138215, 0.40801486793756486, 0.39823750237226485, 0.3862608443915844, 0.3800479968905449, 0.3706626738011837, 0.36037536128759384, 0.353274334526062, 0.34485843165516855, 0.33401546115279196, 0.32808917070627214, 0.3204532278239727, 0.3119360207676887, 0.305154470667243, 0.2967636270463467, 0.2887235942006111, 0.2815081492364407, 0.27090359259545804, 0.26164924938082695, 0.25764619218707085, 0.24742279767096043, 0.24172174341082572, 0.2348580233335495, 0.2272058101475239, 0.22135768200755118, 0.21246716223359108, 0.20563042821586133, 0.19968844935894012, 0.19170186981856824, 0.18627422936558724, 0.1782000934779644, 0.17250456180870533, 0.16441832840293646, 0.16104617184102535, 0.154823574821651, 0.15007829356491564, 0.14314682412147522, 0.13540629065334797, 0.1316422154843807, 0.12595085943639278, 0.12362171813696622, 0.11334044750928879], 'acc': [0.581225, 0.5934, 0.605825, 0.614125, 0.622825, 0.631375, 0.636675, 0.643725, 0.650475, 0.65655, 0.663175, 0.670825, 0.676625, 0.68155, 0.68715, 0.69395, 0.697175, 0.7034, 0.7092, 0.7097, 0.71795, 0.72325, 0.727875, 0.731075, 0.735375, 0.7404, 0.742575, 0.751075, 0.755275, 0.757275, 0.76165, 0.765775, 0.76945, 0.773725, 0.779475, 0.78125, 0.7851, 0.78885, 0.792525, 0.7972, 0.80025, 0.803075, 0.808275, 0.81165, 0.81275, 0.818375, 0.8217, 0.8249, 0.829175, 0.832175, 0.8365, 0.840825, 0.84115, 0.8447, 0.8477, 0.853325, 0.854875, 0.8581, 0.861725, 0.864875, 0.86735, 0.87095, 0.87385, 0.87775, 0.880975, 0.8837, 0.88735, 0.891875, 0.89225, 0.8949, 0.899675, 0.90215, 0.905075, 0.90815, 0.90985, 0.913475, 0.91735, 0.91845, 0.922025, 0.92385, 0.9282, 0.929475, 0.931875, 0.935425, 0.937325, 0.938425, 0.943075, 0.94435, 0.947825, 0.949875, 0.953575, 0.9532, 0.955275, 0.958325, 0.9603, 0.9628, 0.963775, 0.965775, 0.965975, 0.970825]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss: 1.6917810311317445\n",
            "validation accuracy: 0.6665\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}