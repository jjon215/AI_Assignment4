{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Third_Arch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW_2/blob/master/Third_Arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "69ZA9SmGCPpY",
        "colab_type": "code",
        "outputId": "263603e4-cf59-4099-f51b-bc79afc145ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4498
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False, \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06,  \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  \n",
        "        zoom_range=0.,  \n",
        "        channel_shift_range=0.,  \n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  \n",
        "        horizontal_flip=True,  # flip images\n",
        "        vertical_flip=False,  # flip images\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss is :', score[0])\n",
        "print('Test accuracy is :', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('Validation loss:',History.history['val_loss'][-1])\n",
        "print('Validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 39s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 20s 511us/step - loss: 1.8982 - acc: 0.2967\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 397us/step - loss: 1.6030 - acc: 0.4137\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 417us/step - loss: 1.4797 - acc: 0.4640\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 394us/step - loss: 1.4015 - acc: 0.4944\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 420us/step - loss: 1.3364 - acc: 0.5193\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 16s 393us/step - loss: 1.2744 - acc: 0.5440\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 17s 413us/step - loss: 1.2346 - acc: 0.5602\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 21s 517us/step - loss: 1.1881 - acc: 0.5758\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 32s 794us/step - loss: 1.1526 - acc: 0.5943\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 30s 742us/step - loss: 1.1245 - acc: 0.6022\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 25s 625us/step - loss: 0.9860 - acc: 0.6540 - val_loss: 0.9037 - val_acc: 0.6881\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 29s 722us/step - loss: 0.9495 - acc: 0.6644 - val_loss: 0.8739 - val_acc: 0.6953\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 33s 816us/step - loss: 0.9088 - acc: 0.6822 - val_loss: 0.8504 - val_acc: 0.7041\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 27s 672us/step - loss: 0.8777 - acc: 0.6945 - val_loss: 0.8090 - val_acc: 0.7179\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 34s 844us/step - loss: 0.8376 - acc: 0.7038 - val_loss: 0.7912 - val_acc: 0.7278\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 27s 684us/step - loss: 0.8117 - acc: 0.7156 - val_loss: 0.7769 - val_acc: 0.7295\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 30s 738us/step - loss: 0.7854 - acc: 0.7254 - val_loss: 0.7551 - val_acc: 0.7410\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 31s 768us/step - loss: 0.7590 - acc: 0.7341 - val_loss: 0.7513 - val_acc: 0.7377\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 27s 682us/step - loss: 0.7388 - acc: 0.7412 - val_loss: 0.7309 - val_acc: 0.7497\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 37s 937us/step - loss: 0.7125 - acc: 0.7515 - val_loss: 0.7147 - val_acc: 0.7562\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 28s 707us/step - loss: 0.6892 - acc: 0.7573 - val_loss: 0.7401 - val_acc: 0.7469\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 32s 798us/step - loss: 0.6738 - acc: 0.7643 - val_loss: 0.7010 - val_acc: 0.7568\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 30s 749us/step - loss: 0.6512 - acc: 0.7731 - val_loss: 0.6842 - val_acc: 0.7636\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 28s 690us/step - loss: 0.6335 - acc: 0.7776 - val_loss: 0.6821 - val_acc: 0.7633\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 34s 846us/step - loss: 0.6115 - acc: 0.7850 - val_loss: 0.6737 - val_acc: 0.7714\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 27s 665us/step - loss: 0.5943 - acc: 0.7912 - val_loss: 0.6592 - val_acc: 0.7720\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 32s 803us/step - loss: 0.5815 - acc: 0.7956 - val_loss: 0.6514 - val_acc: 0.7752\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 29s 734us/step - loss: 0.5627 - acc: 0.7992 - val_loss: 0.6632 - val_acc: 0.7725\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 29s 714us/step - loss: 0.5486 - acc: 0.8070 - val_loss: 0.6480 - val_acc: 0.7831\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 35s 876us/step - loss: 0.5397 - acc: 0.8095 - val_loss: 0.6491 - val_acc: 0.7805\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 34s 861us/step - loss: 0.5256 - acc: 0.8171 - val_loss: 0.6392 - val_acc: 0.7809\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 34s 859us/step - loss: 0.5049 - acc: 0.8225 - val_loss: 0.6402 - val_acc: 0.7836\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.4943 - acc: 0.8252 - val_loss: 0.6356 - val_acc: 0.7871\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 35s 868us/step - loss: 0.4800 - acc: 0.8297 - val_loss: 0.6646 - val_acc: 0.7796\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 34s 850us/step - loss: 0.4705 - acc: 0.8350 - val_loss: 0.6434 - val_acc: 0.7853\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 34s 851us/step - loss: 0.4577 - acc: 0.8381 - val_loss: 0.6355 - val_acc: 0.7866\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 34s 854us/step - loss: 0.4456 - acc: 0.8420 - val_loss: 0.6420 - val_acc: 0.7864\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 34s 853us/step - loss: 0.4310 - acc: 0.8458 - val_loss: 0.6283 - val_acc: 0.7910\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 34s 858us/step - loss: 0.4278 - acc: 0.8479 - val_loss: 0.6486 - val_acc: 0.7832\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 34s 862us/step - loss: 0.4151 - acc: 0.8530 - val_loss: 0.6424 - val_acc: 0.7867\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.4070 - acc: 0.8554 - val_loss: 0.6591 - val_acc: 0.7907\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 35s 873us/step - loss: 0.3924 - acc: 0.8595 - val_loss: 0.6424 - val_acc: 0.7921\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 34s 862us/step - loss: 0.3841 - acc: 0.8630 - val_loss: 0.6339 - val_acc: 0.7934\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 35s 867us/step - loss: 0.3788 - acc: 0.8658 - val_loss: 0.6295 - val_acc: 0.7944\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 34s 859us/step - loss: 0.3664 - acc: 0.8699 - val_loss: 0.6321 - val_acc: 0.7991\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 35s 873us/step - loss: 0.3546 - acc: 0.8734 - val_loss: 0.6299 - val_acc: 0.7967\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 33s 828us/step - loss: 0.3465 - acc: 0.8768 - val_loss: 0.6343 - val_acc: 0.7963\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 32s 812us/step - loss: 0.3391 - acc: 0.8801 - val_loss: 0.6596 - val_acc: 0.7912\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 33s 818us/step - loss: 0.3324 - acc: 0.8821 - val_loss: 0.6514 - val_acc: 0.7908\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 33s 815us/step - loss: 0.3250 - acc: 0.8831 - val_loss: 0.6594 - val_acc: 0.7918\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 35s 878us/step - loss: 0.3174 - acc: 0.8871 - val_loss: 0.6561 - val_acc: 0.7922\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 35s 863us/step - loss: 0.3153 - acc: 0.8887 - val_loss: 0.6704 - val_acc: 0.7926\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 34s 858us/step - loss: 0.3051 - acc: 0.8902 - val_loss: 0.6473 - val_acc: 0.7948\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.3000 - acc: 0.8930 - val_loss: 0.6518 - val_acc: 0.7951\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.2901 - acc: 0.8966 - val_loss: 0.6461 - val_acc: 0.7997\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 34s 855us/step - loss: 0.2823 - acc: 0.8990 - val_loss: 0.6742 - val_acc: 0.7958\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 37s 919us/step - loss: 0.2731 - acc: 0.9052 - val_loss: 0.6624 - val_acc: 0.7974\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 36s 890us/step - loss: 0.2722 - acc: 0.9008 - val_loss: 0.6657 - val_acc: 0.7960\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 35s 867us/step - loss: 0.2652 - acc: 0.9047 - val_loss: 0.6658 - val_acc: 0.7960\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 35s 879us/step - loss: 0.2646 - acc: 0.9066 - val_loss: 0.6635 - val_acc: 0.7975\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 35s 866us/step - loss: 0.2561 - acc: 0.9087 - val_loss: 0.6796 - val_acc: 0.7981\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 35s 866us/step - loss: 0.2486 - acc: 0.9101 - val_loss: 0.6799 - val_acc: 0.8002\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 34s 862us/step - loss: 0.2491 - acc: 0.9106 - val_loss: 0.6836 - val_acc: 0.8010\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.2481 - acc: 0.9116 - val_loss: 0.6706 - val_acc: 0.7987\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.2360 - acc: 0.9151 - val_loss: 0.6773 - val_acc: 0.8014\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 34s 855us/step - loss: 0.2387 - acc: 0.9144 - val_loss: 0.6901 - val_acc: 0.7966\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 35s 877us/step - loss: 0.2346 - acc: 0.9160 - val_loss: 0.6815 - val_acc: 0.8031\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 34s 858us/step - loss: 0.2229 - acc: 0.9193 - val_loss: 0.6913 - val_acc: 0.7996\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 35s 867us/step - loss: 0.2224 - acc: 0.9197 - val_loss: 0.6976 - val_acc: 0.7960\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 35s 868us/step - loss: 0.2143 - acc: 0.9241 - val_loss: 0.7248 - val_acc: 0.7959\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 35s 866us/step - loss: 0.2148 - acc: 0.9244 - val_loss: 0.6996 - val_acc: 0.8024\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 34s 851us/step - loss: 0.2189 - acc: 0.9214 - val_loss: 0.6789 - val_acc: 0.8023\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 32s 801us/step - loss: 0.2086 - acc: 0.9254 - val_loss: 0.6968 - val_acc: 0.7992\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 34s 856us/step - loss: 0.2062 - acc: 0.9251 - val_loss: 0.7106 - val_acc: 0.7989\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 34s 856us/step - loss: 0.2008 - acc: 0.9273 - val_loss: 0.7238 - val_acc: 0.7975\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 35s 865us/step - loss: 0.2020 - acc: 0.9276 - val_loss: 0.7182 - val_acc: 0.7988\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 35s 870us/step - loss: 0.1974 - acc: 0.9299 - val_loss: 0.7214 - val_acc: 0.7978\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 35s 875us/step - loss: 0.1963 - acc: 0.9307 - val_loss: 0.7038 - val_acc: 0.7999\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 35s 863us/step - loss: 0.1894 - acc: 0.9328 - val_loss: 0.7233 - val_acc: 0.8019\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 35s 872us/step - loss: 0.1843 - acc: 0.9348 - val_loss: 0.7195 - val_acc: 0.8004\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 35s 868us/step - loss: 0.1873 - acc: 0.9335 - val_loss: 0.6995 - val_acc: 0.7979\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 34s 862us/step - loss: 0.1812 - acc: 0.9362 - val_loss: 0.7360 - val_acc: 0.7959\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 35s 872us/step - loss: 0.1795 - acc: 0.9369 - val_loss: 0.7280 - val_acc: 0.7972\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 35s 872us/step - loss: 0.1812 - acc: 0.9353 - val_loss: 0.7242 - val_acc: 0.8007\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 35s 874us/step - loss: 0.1804 - acc: 0.9356 - val_loss: 0.7126 - val_acc: 0.7995\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 35s 871us/step - loss: 0.1727 - acc: 0.9381 - val_loss: 0.7323 - val_acc: 0.8010\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 35s 868us/step - loss: 0.1767 - acc: 0.9386 - val_loss: 0.7271 - val_acc: 0.8027\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.1713 - acc: 0.9398 - val_loss: 0.7286 - val_acc: 0.8027\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 35s 863us/step - loss: 0.1685 - acc: 0.9396 - val_loss: 0.7309 - val_acc: 0.8002\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.1672 - acc: 0.9408 - val_loss: 0.7150 - val_acc: 0.7999\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 35s 865us/step - loss: 0.1689 - acc: 0.9402 - val_loss: 0.7266 - val_acc: 0.8000\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 34s 845us/step - loss: 0.1607 - acc: 0.9422 - val_loss: 0.7546 - val_acc: 0.8003\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 34s 840us/step - loss: 0.1646 - acc: 0.9426 - val_loss: 0.7442 - val_acc: 0.8008\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 36s 903us/step - loss: 0.1641 - acc: 0.9423 - val_loss: 0.7390 - val_acc: 0.7997\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 36s 900us/step - loss: 0.1555 - acc: 0.9446 - val_loss: 0.7554 - val_acc: 0.7983\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.1573 - acc: 0.9438 - val_loss: 0.7501 - val_acc: 0.8007\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 33s 816us/step - loss: 0.1507 - acc: 0.9466 - val_loss: 0.7632 - val_acc: 0.8001\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.1530 - acc: 0.9453 - val_loss: 0.7698 - val_acc: 0.7995\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 35s 867us/step - loss: 0.1523 - acc: 0.9473 - val_loss: 0.7570 - val_acc: 0.8004\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 35s 863us/step - loss: 0.1516 - acc: 0.9459 - val_loss: 0.7589 - val_acc: 0.8006\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 34s 859us/step - loss: 0.1522 - acc: 0.9470 - val_loss: 0.7475 - val_acc: 0.8056\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 35s 867us/step - loss: 0.1475 - acc: 0.9469 - val_loss: 0.7418 - val_acc: 0.8011\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 34s 858us/step - loss: 0.1432 - acc: 0.9500 - val_loss: 0.7727 - val_acc: 0.8029\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.1433 - acc: 0.9491 - val_loss: 0.7820 - val_acc: 0.7966\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 35s 864us/step - loss: 0.1460 - acc: 0.9484 - val_loss: 0.7524 - val_acc: 0.8023\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 33s 821us/step - loss: 0.1377 - acc: 0.9503 - val_loss: 0.7581 - val_acc: 0.8031\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 35s 871us/step - loss: 0.1432 - acc: 0.9488 - val_loss: 0.7597 - val_acc: 0.8007\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 34s 860us/step - loss: 0.1392 - acc: 0.9512 - val_loss: 0.7660 - val_acc: 0.8011\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 34s 845us/step - loss: 0.1372 - acc: 0.9504 - val_loss: 0.7671 - val_acc: 0.8013\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.1362 - acc: 0.9511 - val_loss: 0.7928 - val_acc: 0.8024\n",
            "Test loss is : 0.7928498234272003\n",
            "Test accuracy is : 0.8024\n",
            "[0.7928498234272003, 0.8024]\n",
            "{'val_loss': [0.9037190011978149, 0.8738614604949951, 0.8503811690330505, 0.8089589131355286, 0.791231743812561, 0.7768770838737488, 0.7550566570281982, 0.7513160561561585, 0.7308786981582641, 0.7147316179275512, 0.7400512957572937, 0.7009966662406921, 0.6842442316532135, 0.6820826051712036, 0.6736564578533173, 0.6592423437595367, 0.6513511112213135, 0.663189741230011, 0.6479520698547363, 0.6490570166110993, 0.6392041689395904, 0.6401966005325317, 0.6356006024837494, 0.6645548370838166, 0.6434472674369812, 0.6354689214229584, 0.6420195287704468, 0.6283158924102783, 0.6485666803836823, 0.6424082566261291, 0.6590762383460999, 0.6423776606559753, 0.6339457032680511, 0.6294850667953491, 0.6321307514190674, 0.6298702947616577, 0.6343190667152405, 0.6595609558582306, 0.6513547319412232, 0.6594183992862701, 0.6560553452968597, 0.6703743040084839, 0.6472668734073639, 0.6518289979457855, 0.646112880897522, 0.674210551404953, 0.6624355380535125, 0.6657324722051621, 0.6657514413833618, 0.6635152415275574, 0.6795638920783996, 0.6799010547161102, 0.6836186326503754, 0.6705748813390732, 0.6773204161643982, 0.6901168570518493, 0.6814608668804168, 0.6913007221221924, 0.6976222060680389, 0.7248039076328278, 0.6996224006891251, 0.6789005829334259, 0.6968197921514511, 0.7106180315256119, 0.7238418471574783, 0.7181727180719376, 0.7214347508430481, 0.7037829689979553, 0.7232720460414886, 0.7195351430654525, 0.6994741873025894, 0.7360422748565674, 0.7279534316778183, 0.7242468581676483, 0.7125886842966079, 0.7323122408390045, 0.727080798625946, 0.7285980885028839, 0.7308509021520615, 0.7149689103603363, 0.7265983200311661, 0.7545601470947265, 0.7442246141195297, 0.7389781679153442, 0.7553516251087189, 0.7501218938589096, 0.7631932403087616, 0.7697849924564362, 0.7570341377735138, 0.758902347278595, 0.7475259692430496, 0.7417725835084915, 0.7727122645497322, 0.781996664428711, 0.7523812101125718, 0.7580830070972443, 0.7597077685832977, 0.7660301112174988, 0.7670982868909836, 0.7928498234272003], 'val_acc': [0.6881, 0.6953, 0.7041, 0.7179, 0.7278, 0.7295, 0.741, 0.7377, 0.7497, 0.7562, 0.7469, 0.7568, 0.7636, 0.7633, 0.7714, 0.772, 0.7752, 0.7725, 0.7831, 0.7805, 0.7809, 0.7836, 0.7871, 0.7796, 0.7853, 0.7866, 0.7864, 0.791, 0.7832, 0.7867, 0.7907, 0.7921, 0.7934, 0.7944, 0.7991, 0.7967, 0.7963, 0.7912, 0.7908, 0.7918, 0.7922, 0.7926, 0.7948, 0.7951, 0.7997, 0.7958, 0.7974, 0.796, 0.796, 0.7975, 0.7981, 0.8002, 0.801, 0.7987, 0.8014, 0.7966, 0.8031, 0.7996, 0.796, 0.7959, 0.8024, 0.8023, 0.7992, 0.7989, 0.7975, 0.7988, 0.7978, 0.7999, 0.8019, 0.8004, 0.7979, 0.7959, 0.7972, 0.8007, 0.7995, 0.801, 0.8027, 0.8027, 0.8002, 0.7999, 0.8, 0.8003, 0.8008, 0.7997, 0.7983, 0.8007, 0.8001, 0.7995, 0.8004, 0.8006, 0.8056, 0.8011, 0.8029, 0.7966, 0.8023, 0.8031, 0.8007, 0.8011, 0.8013, 0.8024], 'loss': [0.9860258723258972, 0.9495277956724167, 0.9088014785528183, 0.8776702908039093, 0.837556396317482, 0.8117003705263138, 0.7853912608861924, 0.7589574479579926, 0.7387630136728287, 0.7125106256604194, 0.6892161607027054, 0.673765784239769, 0.6512093531131744, 0.6334628426909447, 0.6114948861718178, 0.5943497668504715, 0.5815291154623031, 0.5627041974425316, 0.5486363014936447, 0.5396788664460183, 0.5256028908252716, 0.5049211207926273, 0.49426202063560487, 0.47997118562459945, 0.47053083043694494, 0.4577305390834808, 0.44560306706428526, 0.4310065846323967, 0.4278144386649132, 0.4150622545957565, 0.40696209631562236, 0.39236580121517184, 0.38412359674572943, 0.378817447501421, 0.36635528057813643, 0.3546476368486881, 0.3465089141309261, 0.33910451065301894, 0.33236037264466284, 0.3249910336792469, 0.3174373003900051, 0.3152606668770313, 0.30512864648103716, 0.2999855525940657, 0.29005432656407354, 0.2823170965135097, 0.27307393366098404, 0.27224141416251657, 0.2651733697682619, 0.2645569851875305, 0.2560906526952982, 0.24863516685962678, 0.2491006342291832, 0.24810519197583197, 0.23600595707595348, 0.23871660017967225, 0.23458879471570254, 0.22292092501819133, 0.22244466352760792, 0.21428215266168119, 0.21480804805904627, 0.21888595904111863, 0.20860101673305034, 0.20615939940065145, 0.20077508111596107, 0.20199950861781835, 0.1974265023842454, 0.19627192979305982, 0.1894327411174774, 0.18431388524472714, 0.18729469226449727, 0.18119516166821123, 0.1795135230153799, 0.1812204972654581, 0.18040543479025364, 0.17267650167942047, 0.17668575234264136, 0.1713335107602179, 0.1684519443511963, 0.16715713700726628, 0.16888199928849937, 0.16073662077486514, 0.16463196481913328, 0.1640693048119545, 0.1555168964728713, 0.1573170178450644, 0.1507474258825183, 0.15298097197562457, 0.15225625882446767, 0.15161120474375783, 0.15216799984537066, 0.14745249132737517, 0.143210234747082, 0.1433387977723032, 0.14596478083208203, 0.13773132226467133, 0.14321009022444486, 0.1392140186522156, 0.13717580023556947, 0.1362378718674183], 'acc': [0.654, 0.66445, 0.682225, 0.6945, 0.703825, 0.715575, 0.725425, 0.734125, 0.741225, 0.751525, 0.757275, 0.76435, 0.77305, 0.777575, 0.784975, 0.791175, 0.795575, 0.799175, 0.806975, 0.809475, 0.817125, 0.822475, 0.825175, 0.8297, 0.83505, 0.838125, 0.84205, 0.8458, 0.8479, 0.853, 0.855425, 0.859475, 0.862975, 0.86585, 0.869875, 0.873375, 0.876825, 0.8801, 0.88205, 0.883125, 0.88705, 0.88865, 0.8902, 0.893025, 0.896625, 0.899025, 0.905225, 0.900775, 0.9047, 0.90665, 0.90865, 0.910075, 0.91055, 0.9116, 0.9151, 0.9144, 0.91595, 0.9193, 0.9197, 0.924075, 0.92445, 0.9214, 0.9254, 0.92505, 0.92725, 0.927575, 0.929925, 0.93075, 0.932825, 0.934775, 0.93345, 0.9362, 0.936925, 0.93525, 0.9356, 0.938075, 0.938575, 0.93985, 0.939625, 0.940825, 0.9402, 0.942175, 0.9426, 0.942325, 0.9446, 0.9438, 0.946625, 0.945275, 0.94735, 0.9459, 0.947, 0.94695, 0.949975, 0.949125, 0.948375, 0.9503, 0.94885, 0.951175, 0.9504, 0.951075]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBIsABgSLAAY+gDhH7+971KNCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.7928498234272003\n",
            "Validation accuracy: 0.8024\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}