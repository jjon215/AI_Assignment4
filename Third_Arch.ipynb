{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Third_Arch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjon215/MLHW_2/blob/master/Third_Arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "69ZA9SmGCPpY",
        "colab_type": "code",
        "outputId": "cd77878f-7a72-4881-e030-c22d26118522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1887
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "x_train = list(x_train)\n",
        "y_train = list(y_train)\n",
        "\n",
        "val_loss = list()\n",
        "val_acc = list()\n",
        "\n",
        "x_val = np.array(x_train[4*10000:(4+1)*10000])\n",
        "y_val = np.array(y_train[4*10000:(4+1)*10000])\n",
        "  \n",
        "x_tra = np.array(x_train[0:4*10000]+x_train[(4+1)*10000:50000])\n",
        "y_tra = np.array(y_train[0:4*10000]+y_train[(4+1)*10000:50000])\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_tra.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "   \n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False, \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False, \n",
        "        zca_epsilon=1e-06,  \n",
        "        rotation_range=0, \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  \n",
        "        zoom_range=0.,  \n",
        "        channel_shift_range=0.,  \n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  \n",
        "        horizontal_flip=True,  # flip images\n",
        "        vertical_flip=False,  # flip images\n",
        "        rescale=None,\n",
        "        preprocessing_function=None,\n",
        "        data_format=None,\n",
        "        validation_split=0.0)\n",
        "\n",
        "datagen.fit(x_tra)\n",
        "\n",
        "for e in range(10):\n",
        "    batches = 0\n",
        "    for x_batch, y_batch in datagen.flow(x_tra, y_tra, batch_size=40000):\n",
        "        model.fit(x_batch, y_batch)\n",
        "        batches += 1\n",
        "        if batches >= 1:\n",
        "\n",
        "            break\n",
        "\n",
        "History = model.fit(x_tra, y_tra,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,                    \n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss is :', score[0])\n",
        "print('Test accuracy is :', score[1])\n",
        "print(score)\n",
        "print(History.history)\n",
        "\n",
        "plotaccuracy = plt.plot(range(1,epochs+1),History.history['acc'],range(1,epochs+1),History.history['val_acc'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Train Accuracy','Test Accuracy'))\n",
        "plt.show(plotaccuracy)\n",
        "\n",
        "print('Validation loss:',History.history['val_loss'][-1])\n",
        "print('Validation accuracy:',History.history['val_acc'][-1])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 12s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 220s 5ms/step - loss: 1.8789 - acc: 0.3081\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 226s 6ms/step - loss: 1.5963 - acc: 0.4166\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 245s 6ms/step - loss: 1.4922 - acc: 0.4573\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 225s 6ms/step - loss: 1.4133 - acc: 0.4870\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 237s 6ms/step - loss: 1.3523 - acc: 0.5114\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 216s 5ms/step - loss: 1.2968 - acc: 0.5346\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 247s 6ms/step - loss: 1.2479 - acc: 0.5536\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 225s 6ms/step - loss: 1.2057 - acc: 0.5682\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 248s 6ms/step - loss: 1.1654 - acc: 0.5837\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 226s 6ms/step - loss: 1.1385 - acc: 0.5951\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 1.0105 - acc: 0.6435 - val_loss: 0.9235 - val_acc: 0.6817\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 234s 6ms/step - loss: 0.9748 - acc: 0.6553 - val_loss: 0.9100 - val_acc: 0.6862\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 239s 6ms/step - loss: 0.9342 - acc: 0.6708 - val_loss: 0.8895 - val_acc: 0.6935\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.9042 - acc: 0.6812 - val_loss: 0.8651 - val_acc: 0.6983\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 0.8754 - acc: 0.6924 - val_loss: 0.8478 - val_acc: 0.7068\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 239s 6ms/step - loss: 0.8461 - acc: 0.7017 - val_loss: 0.8132 - val_acc: 0.7157\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.8222 - acc: 0.7117 - val_loss: 0.8025 - val_acc: 0.7208\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.7964 - acc: 0.7189 - val_loss: 0.8011 - val_acc: 0.7227\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 0.7739 - acc: 0.7274 - val_loss: 0.7536 - val_acc: 0.7379\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 237s 6ms/step - loss: 0.7475 - acc: 0.7374 - val_loss: 0.7368 - val_acc: 0.7435\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 238s 6ms/step - loss: 0.7274 - acc: 0.7443 - val_loss: 0.7399 - val_acc: 0.7435\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.7086 - acc: 0.7497 - val_loss: 0.7098 - val_acc: 0.7547\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 244s 6ms/step - loss: 0.6888 - acc: 0.7595 - val_loss: 0.6989 - val_acc: 0.7599\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 243s 6ms/step - loss: 0.6706 - acc: 0.7634 - val_loss: 0.7219 - val_acc: 0.7510\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 0.6501 - acc: 0.7714 - val_loss: 0.6923 - val_acc: 0.7583\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.6282 - acc: 0.7806 - val_loss: 0.6864 - val_acc: 0.7630\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 0.6197 - acc: 0.7799 - val_loss: 0.6716 - val_acc: 0.7703\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 238s 6ms/step - loss: 0.5981 - acc: 0.7893 - val_loss: 0.6747 - val_acc: 0.7712\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 234s 6ms/step - loss: 0.5857 - acc: 0.7947 - val_loss: 0.6621 - val_acc: 0.7735\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.5674 - acc: 0.8018 - val_loss: 0.6564 - val_acc: 0.7780\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 247s 6ms/step - loss: 0.5537 - acc: 0.8054 - val_loss: 0.6661 - val_acc: 0.7728\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 236s 6ms/step - loss: 0.5373 - acc: 0.8104 - val_loss: 0.6557 - val_acc: 0.7771\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 244s 6ms/step - loss: 0.5259 - acc: 0.8153 - val_loss: 0.6740 - val_acc: 0.7703\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 240s 6ms/step - loss: 0.5149 - acc: 0.8182 - val_loss: 0.6700 - val_acc: 0.7767\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 238s 6ms/step - loss: 0.4995 - acc: 0.8249 - val_loss: 0.6560 - val_acc: 0.7778\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 239s 6ms/step - loss: 0.4826 - acc: 0.8298 - val_loss: 0.6425 - val_acc: 0.7867\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 236s 6ms/step - loss: 0.4750 - acc: 0.8302 - val_loss: 0.6432 - val_acc: 0.7872\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 240s 6ms/step - loss: 0.4583 - acc: 0.8370 - val_loss: 0.6452 - val_acc: 0.7857\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 244s 6ms/step - loss: 0.4537 - acc: 0.8387 - val_loss: 0.6539 - val_acc: 0.7827\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 245s 6ms/step - loss: 0.4369 - acc: 0.8446 - val_loss: 0.6479 - val_acc: 0.7881\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 242s 6ms/step - loss: 0.4312 - acc: 0.8469 - val_loss: 0.6436 - val_acc: 0.7855\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 241s 6ms/step - loss: 0.4189 - acc: 0.8515 - val_loss: 0.6555 - val_acc: 0.7859\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 243s 6ms/step - loss: 0.4052 - acc: 0.8547 - val_loss: 0.6601 - val_acc: 0.7876\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 243s 6ms/step - loss: 0.4029 - acc: 0.8551 - val_loss: 0.6348 - val_acc: 0.7929\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 236s 6ms/step - loss: 0.3903 - acc: 0.8618 - val_loss: 0.6505 - val_acc: 0.7912\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 233s 6ms/step - loss: 0.3783 - acc: 0.8647 - val_loss: 0.6403 - val_acc: 0.7944\n",
            "Epoch 37/100\n",
            "21088/40000 [==============>...............] - ETA: 1:44 - loss: 0.3665 - acc: 0.8722Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}